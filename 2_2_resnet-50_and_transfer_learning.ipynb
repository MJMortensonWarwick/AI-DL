{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0Zq5HH7v2AN5os822ONyA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJMortensonWarwick/AI-DL/blob/main/2_2_resnet-50_and_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction and Transfer Learning with ResNet-50\n",
        "Here we will use the ResNet-50 model in full (no new training). Let's start by adding a picture of an elephant from the internet (available in the Github) "
      ],
      "metadata": {
        "id": "cg7GjqsOO2eg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJtwObPpOzEA"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will call the model, load our image, pre-process it in the fashion ResNet expects and then predict it. Unsuprisingly this is an easy task for ResNet."
      ],
      "metadata": {
        "id": "fGlA-1eoP58b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "img_path = '/content/elephant.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6boYRceMP5NG",
        "outputId": "69d56974-ff86-4bbb-b897-cd30b721b390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [('n02504458', 'African_elephant', 0.42291683), ('n02504013', 'Indian_elephant', 0.3574935), ('n01871265', 'tusker', 0.21937707)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction is \"african elephant\" which is correct. We can  see \"indian elephant\" is a close second. \n",
        "\n",
        "Let's expand this by instead implementing a transfer learning model. We'll remove the dense neural network layers at the end (FC layers) and learn some new ones for our dataset."
      ],
      "metadata": {
        "id": "C8VsvhVtTei-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "from tensorflow.keras.applications.resnet import preprocess_input, ResNet50\n",
        "import tensorflow.keras as K \n",
        "import tensorflow as tf\n",
        "\n",
        "def preprocess_res(X, Y):\n",
        "    X_out = preprocess_input(X)\n",
        "    Y_out = K.utils.to_categorical(Y, 10)\n",
        "    return X_out, Y_out\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "x_train, y_train = preprocess_res(x_train, y_train)\n",
        "x_test, y_test = preprocess_res(x_test, y_test)\n",
        "\n",
        "res_model = ResNet50(include_top=False,\n",
        "                      weights=\"imagenet\",\n",
        "                      input_tensor=K.Input(shape=(32, 32, 3)))\n",
        "\n",
        "for layer in res_model.layers[:143]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = K.models.Sequential()\n",
        "model.add(res_model)\n",
        "model.add(K.layers.Flatten())\n",
        "model.add(K.layers.Dropout(0.5))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Dense(64, activation='relu'))\n",
        "model.add(K.layers.Dropout(0.5))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=K.optimizers.RMSprop(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=1,\n",
        "                        validation_data=(x_test, y_test))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP7LwEPoTe4y",
        "outputId": "541fda42-4276-42d4-b44b-7263b42f7cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 2075s 1s/step - loss: 1.3963 - accuracy: 0.5406 - val_loss: 1.0369 - val_accuracy: 0.6769\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 2101s 1s/step - loss: 1.1189 - accuracy: 0.6401 - val_loss: 0.9158 - val_accuracy: 0.7059\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 2122s 1s/step - loss: 1.0187 - accuracy: 0.6732 - val_loss: 0.8589 - val_accuracy: 0.7148\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 2123s 1s/step - loss: 0.9374 - accuracy: 0.7001 - val_loss: 0.8458 - val_accuracy: 0.7294\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 2105s 1s/step - loss: 0.8824 - accuracy: 0.7218 - val_loss: 0.8511 - val_accuracy: 0.7298\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 2048)             8192      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                131136    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,727,946\n",
            "Trainable params: 15,112,010\n",
            "Non-trainable params: 8,615,936\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A lot more to unpack. Firstly, we just run a simple function using the ResNet50 functionality again to pre-process our data. \n",
        "\n",
        "Then we again build the ResNet model but this time with an import difference ... _include\\_top=False_. This means we have removed the dense (FC) layers that end the model and make predictions. We replace these with our own. \n",
        "\n",
        "We also then change the parameter on these ResNet layers to be _trainable=False_. Through doing so, the ResNet part will not change any weights during training, we'll use the ones the author's learned. In other words, the ResNet model is now a feature extractor that preprocesses our data before we use a more vanilla neural net to make predicitons.\n",
        "\n",
        "Finally, we add layers as we've seen before and compile and run (and wait ... its a big model)."
      ],
      "metadata": {
        "id": "f54K2Fu2fy86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once trained we can use the model like we would any other:"
      ],
      "metadata": {
        "id": "tjvmREGVP-FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RCiknueQcFb",
        "outputId": "4175ff33-6f96-4ad6-d549-81c692254091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 44s 139ms/step - loss: 0.8511 - accuracy: 0.7298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8511039018630981, 0.7297999858856201]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All done ðŸ¥³"
      ],
      "metadata": {
        "id": "gMhgbT0sQnyL"
      }
    }
  ]
}