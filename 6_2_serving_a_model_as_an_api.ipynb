{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYNWNgdWbpkn/suB4Jiikc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJMortensonWarwick/AI-DL/blob/main/6_2_serving_a_model_as_an_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serving a Model as an API Endpoint\n",
        "Here we'll serve our original model over an API. We'll start by rebuilding the model:"
      ],
      "metadata": {
        "id": "1w0R5aBd9dn4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ByUuWyA06iN",
        "outputId": "22f9c5a8-e011-4cef-8703-4be96a59cb48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25657.6582 - mse: 25657.6582\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25653.5898 - mse: 25653.5898\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25649.5293 - mse: 25649.5293\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25645.0547 - mse: 25645.0547\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25640.4805 - mse: 25640.4805\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25635.6680 - mse: 25635.6680\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25630.6699 - mse: 25630.6699\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25625.6621 - mse: 25625.6621\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25620.4004 - mse: 25620.4004\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25614.9199 - mse: 25614.9199\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25608.9902 - mse: 25608.9902\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25602.8301 - mse: 25602.8301\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25596.6055 - mse: 25596.6055\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25589.8105 - mse: 25589.8105\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25582.9453 - mse: 25582.9453\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25575.6406 - mse: 25575.6406\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25568.2422 - mse: 25568.2422\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25560.3691 - mse: 25560.3691\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25551.9492 - mse: 25551.9492\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25543.3652 - mse: 25543.3652\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25534.5957 - mse: 25534.5957\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25525.5176 - mse: 25525.5176\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25515.7148 - mse: 25515.7148\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25505.1641 - mse: 25505.1641\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25495.1992 - mse: 25495.1992\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25484.2656 - mse: 25484.2656\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25472.6543 - mse: 25472.6543\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25460.4766 - mse: 25460.4766\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25448.5508 - mse: 25448.5508\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25435.5352 - mse: 25435.5352\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25422.1250 - mse: 25422.1250\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25408.1348 - mse: 25408.1348\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25393.3750 - mse: 25393.3750\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25378.2871 - mse: 25378.2871\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25362.9199 - mse: 25362.9199\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25346.1543 - mse: 25346.1543\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25328.8047 - mse: 25328.8047\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25311.3223 - mse: 25311.3223\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25292.2793 - mse: 25292.2793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25273.5859 - mse: 25273.5859\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25253.7148 - mse: 25253.7148\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25233.2578 - mse: 25233.2578\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25211.8379 - mse: 25211.8379\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25189.4141 - mse: 25189.4141\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25165.8594 - mse: 25165.8594\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25143.2793 - mse: 25143.2793\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25118.2852 - mse: 25118.2852\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25093.3496 - mse: 25093.3496\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25067.7109 - mse: 25067.7109\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25039.7207 - mse: 25039.7207\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25012.6152 - mse: 25012.6152\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24983.8105 - mse: 24983.8105\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24954.6992 - mse: 24954.6992\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24923.2695 - mse: 24923.2695\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24892.0371 - mse: 24892.0371\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24859.6133 - mse: 24859.6133\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24825.5566 - mse: 24825.5566\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24792.2109 - mse: 24792.2109\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24756.2852 - mse: 24756.2852\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24719.2773 - mse: 24719.2773\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24682.0234 - mse: 24682.0234\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24643.4199 - mse: 24643.4199\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24603.1543 - mse: 24603.1543\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24561.2402 - mse: 24561.2402\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24520.5156 - mse: 24520.5156\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24476.6855 - mse: 24476.6855\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24432.3945 - mse: 24432.3945\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24385.4297 - mse: 24385.4297\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24339.0234 - mse: 24339.0234\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24291.9648 - mse: 24291.9648\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24239.0996 - mse: 24239.0996\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24190.5449 - mse: 24190.5449\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24137.7617 - mse: 24137.7617\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24084.8223 - mse: 24084.8223\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24028.0703 - mse: 24028.0703\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23974.3203 - mse: 23974.3203\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23916.3301 - mse: 23916.3301\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23857.0547 - mse: 23857.0547\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23795.6504 - mse: 23795.6504\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23734.8027 - mse: 23734.8027\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23671.7598 - mse: 23671.7598\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23610.6543 - mse: 23610.6543\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23540.9941 - mse: 23540.9941\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23476.2656 - mse: 23476.2656\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23408.2598 - mse: 23408.2598\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23338.3223 - mse: 23338.3223\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23268.0020 - mse: 23268.0020\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23194.2559 - mse: 23194.2559\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23119.5098 - mse: 23119.5098\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23046.5684 - mse: 23046.5684\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22971.5059 - mse: 22971.5059\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22891.1094 - mse: 22891.1094\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22810.0391 - mse: 22810.0391\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22733.7891 - mse: 22733.7891\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22648.3750 - mse: 22648.3750\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22566.3223 - mse: 22566.3223\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22480.8047 - mse: 22480.8047\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22395.8457 - mse: 22395.8457\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22300.9395 - mse: 22300.9395\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22219.6895 - mse: 22219.6895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d85531990>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# the code from the last module\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# import the data\n",
        "data = load_diabetes()\n",
        "\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices((data.data, data.target))\n",
        "\n",
        "train_dataset = tf_dataset.take(400)\n",
        "test_dataset = tf_dataset.skip(400)\n",
        "\n",
        "train_batch = train_dataset.batch(50)\n",
        "features, labels = next(iter(train_batch))\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(20, activation=tf.nn.relu, input_shape=(10, )),  # 10 features\n",
        "  tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Keras implementation\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['mse'])\n",
        "\n",
        "model.fit(features, labels, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will save the model to our local session store:"
      ],
      "metadata": {
        "id": "w9Nay-Xl9whO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"ann.pkl\", 'wb') as file:  \n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc4XNaUj1ayI",
        "outputId": "7b8c2139-ace3-4eae-b1a5-741bbfc78e6c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://7e644ee1-bde6-4338-a9c1-24301cbe2be5/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're serving via FastAPI as we have previously. We need to setup our features as a class:"
      ],
      "metadata": {
        "id": "C6MTWaoe92m1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi[all]\n",
        "\n",
        "import pydantic\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Features(BaseModel):\n",
        "    age: float \n",
        "    sex: float \n",
        "    bmi: float \n",
        "    bp: float \n",
        "    s1: float \n",
        "    s2: float \n",
        "    s3: float \n",
        "    s4: float \n",
        "    s5: float \n",
        "    s6: float "
      ],
      "metadata": {
        "id": "gWppcsWc11rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we can build our API. Refer back to the earlier API tutorial if the below in unclear"
      ],
      "metadata": {
        "id": "T8ESDv9L-BrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import pickle\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"ann.pkl\", \"rb\"))\n",
        "\n",
        "@app.post('/predict')\n",
        "def get_music_category(data: Features):\n",
        "    received = data.dict()\n",
        "    age = received['age']\n",
        "    sex = received['sex']\n",
        "    bmi = received['bmi']\n",
        "    bp = received['bp']\n",
        "    s1 = received['s1']\n",
        "    s2 = received['s2']\n",
        "    s3 = received['s3']\n",
        "    s4 = received['s4']\n",
        "    s5 = received['s5']\n",
        "    s6 = received['s6']\n",
        "    tf_dataset = tf.data.Dataset.from_tensor_slices([\n",
        "                                          age, sex, bmi, bp,\n",
        "                                          s1, s2, s3,\n",
        "                                          s4, s5, s6])\n",
        "    test_batch = tf_dataset.batch(1) # the whole dataset\n",
        "    y_pred = model.predict(test_batch)\n",
        "    return {'prediction': y_pred}"
      ],
      "metadata": {
        "id": "CeZeynmD3SUB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly we will use the _colabcode_ package to turn our Colab into an API. In practice we can just use FastAPI directly"
      ],
      "metadata": {
        "id": "mlkJv1pT-PCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colabcode\n",
        "\n",
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "metadata": {
        "id": "Va4FZkAN6Y5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "server.run_app(app=app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZAIX1Jx6jjZ",
        "outputId": "f039f78a-44d7-41ba-d93a-b175fb372e7c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://1df4-34-125-223-241.ngrok.io\" -> \"http://localhost:10000\"\n"
          ]
        }
      ]
    }
  ]
}
